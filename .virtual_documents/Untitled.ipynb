!pip install numpy pandas scikit-learn matplotlib



# Importar las librerías necesarias
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# Cargar el dataset (reemplaza 'dataset.csv' con tu archivo o dataset real)
# Asegúrate de que el archivo esté en el mismo directorio que tu notebook o da la ruta completa
data = pd.read_csv("news.csv.zip")

# Preprocesar los datos (esto depende de tu dataset; ajusta según corresponda)
X = data.drop("target", axis=1)  # Reemplaza 'target' con el nombre de tu variable objetivo
y = data["target"]

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Entrenar un modelo
model = RandomForestClassifier(random_state=42, n_estimators=100)
model.fit(X_train, y_train)

# Hacer predicciones
y_pred = model.predict(X_test)

# Evaluar el modelo
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")
print("Classification Report:")
print(classification_report(y_test, y_pred))



print(data.columns)



# Importar las librerías necesarias
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd

# Combinar las columnas de texto (opcional: depende si quieres usar solo 'text' o ambas)
data['combined_text'] = data['title'] + " " + data['text']

# Convertir el texto a características numéricas usando TfidfVectorizer
vectorizer = TfidfVectorizer(stop_words="english", max_features=5000)  # Limitar a 5000 características para evitar problemas de memoria
X = vectorizer.fit_transform(data['combined_text'])

# Variable objetivo
y = data['label']

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Entrenar un modelo de clasificación (Random Forest en este caso)
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Realizar predicciones
y_pred = model.predict(X_test)

# Evaluar el modelo
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))



X = data.drop(["label", "Unnamed: 0"], axis=1)



import pandas as pd

# Inicializar un diccionario para registrar métricas
metrics = {
    "Epoch": [],
    "Training Loss": [],
    "Validation Loss": [],
    "Accuracy": [],
    "F1": [],
    "Precision": [],
    "Recall": [],
}

# Simular entrenamiento (reemplaza estas simulaciones con tus datos reales)
for epoch in range(1, 5):
    # Añadir los datos por cada época
    metrics["Epoch"].append(epoch)
    metrics["Training Loss"].append(round(0.5 - epoch * 0.05, 6))  # Simulación
    metrics["Validation Loss"].append(round(0.6 - epoch * 0.1, 6))  # Simulación
    metrics["Accuracy"].append(round(0.5 + epoch * 0.1, 6))  # Simulación
    metrics["F1"].append(round(0.5 + epoch * 0.15, 6))  # Simulación
    metrics["Precision"].append(round(0.6 + epoch * 0.1, 6))  # Simulación
    metrics["Recall"].append(round(0.4 + epoch * 0.1, 6))  # Simulación

# Crear un DataFrame con las métricas
df_metrics = pd.DataFrame(metrics)

# Mostrar la tabla
print(df_metrics)



# Guardar las métricas en un archivo CSV
df_metrics.to_csv("metrics.csv", index=False)
print("Las métricas han sido guardadas en metrics.csv")






import matplotlib.pyplot as plt
print(plt.style.available)



plt.style.use('ggplot')  # Cambia por un estilo disponible




pip install seaborn



import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# Cargar el archivo CSV con las métricas
df_metrics = pd.read_csv("metrics.csv")

# Revisar los datos cargados (opcional)
print(df_metrics.head())

# Gráfico de pérdidas con degradados
plt.figure(figsize=(12, 7))
x = df_metrics["Epoch"]

plt.fill_between(x, df_metrics["Training Loss"], color="#FFA07A", alpha=0.4, label="Training Loss")
plt.fill_between(x, df_metrics["Validation Loss"], color="#87CEFA", alpha=0.4, label="Validation Loss")
plt.plot(x, df_metrics["Training Loss"], color="#FF4500", linewidth=2.5, label="Training Loss", marker="o")
plt.plot(x, df_metrics["Validation Loss"], color="#1E90FF", linewidth=2.5, label="Validation Loss", marker="o")

plt.title("Training and Validation Loss per Epoch", fontsize=18, fontweight="bold", color="#4B0082")
plt.xlabel("Epoch", fontsize=14, fontweight="bold", color="#4B0082")
plt.ylabel("Loss", fontsize=14, fontweight="bold", color="#4B0082")
plt.legend(fontsize=12, loc="upper right")
plt.grid(visible=False)
plt.tight_layout()
plt.show()

# Gráfico de métricas de rendimiento
plt.figure(figsize=(12, 7))
metrics = ["Accuracy", "F1", "Precision", "Recall"]
colors = ["#2E8B57", "#8A2BE2", "#FF6347", "#4682B4"]
for i, metric in enumerate(metrics):
    plt.plot(df_metrics["Epoch"], df_metrics[metric], label=metric, color=colors[i], linewidth=2.5, marker="o")

# Estilo del gráfico
plt.title("Performance Metrics per Epoch", fontsize=18, fontweight="bold", color="#4B0082")
plt.xlabel("Epoch", fontsize=14, fontweight="bold", color="#4B0082")
plt.ylabel("Score", fontsize=14, fontweight="bold", color="#4B0082")
plt.legend(fontsize=12, loc="lower right")
plt.grid(color="#D3D3D3", linestyle="--", linewidth=0.5)
plt.tight_layout()
plt.show()









